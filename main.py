from flask import Flask, request, jsonify
from flask_cors import CORS
import os
import sys
from sklearn.feature_extraction.text import TfidfVectorizer
from underthesea import word_tokenize
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics.pairwise import cosine_similarity
from waitress import serve
import logging
import pandas as pd
import torch
from transformers import AutoTokenizer, AutoModel
import mysql.connector
import numpy as np
import random
app = Flask(__name__)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        # Log to console
        logging.StreamHandler(sys.stdout),
        # Log to file
        logging.FileHandler('chatbot.log')
    ]
)
logger = logging.getLogger(__name__)
CORS(app)


def preprocess_vietnamese(text):
    tokens = word_tokenize(text)
    return ' '.join(tokens)


def format_price(price):
    return "{:,.0f}".format(price).replace(',', '.')


def get_effective_price(row, courses_discount):
    """
    Get the effective price considering discounts
    """
    course_id = row['id']
    original_price = row['original_price']

    # Check if course has an active discount
    discount_info = courses_discount[
        (courses_discount['course_id'] == course_id) &
        (courses_discount['is_active'] == True)
        ]

    if not discount_info.empty:
        return discount_info.iloc[0]['discount_price']
    return original_price


def calculate_combined_similarity(courses, courses_discount, text_weight=0.6, rating_weight=0.2, price_weight=0.2,
                                  category_weight=0.9):
    """
    Calculate similarity between courses based on description, rating, and effective price

    Parameters:
    - courses: DataFrame containing 'id', 'description', 'average_rating', and 'original_price'
    - courses_discount: DataFrame containing discount information
    - text_weight: weight for description similarity (default: 0.6)
    - rating_weight: weight for rating similarity (default: 0.2)
    - price_weight: weight for price similarity (default: 0.2)

    Returns:
    - combined similarity matrix
    """
    # Preprocess description
    courses['description'] = courses['description'].apply(preprocess_vietnamese)

    # Calculate text similarity
    tfidf = TfidfVectorizer(
        max_features=3522,
        ngram_range=(1, 2)
    )
    text_vectors = tfidf.fit_transform(courses['description'])
    text_similarity = cosine_similarity(text_vectors)

    # Calculate effective prices considering discounts
    courses['effective_price'] = courses.apply(
        lambda row: get_effective_price(row, courses_discount),
        axis=1
    )
    # Normalize numerical features
    scaler = MinMaxScaler()

    # Handle rating similarity
    ratings = courses[['average_rating']].values
    normalized_ratings = scaler.fit_transform(ratings)
    rating_similarity = 1 - np.abs(normalized_ratings - normalized_ratings.T)

    # Handle price similarity using effective prices
    prices = courses[['effective_price']].values
    normalized_prices = scaler.fit_transform(prices)
    price_similarity = 1 - np.abs(normalized_prices - normalized_prices.T)

    # Handle category similarity: 1 if categories match, 0 if they don't
    categories = courses[['sub_category_id']].values
    category_similarity = np.array([[1 if cat1 == cat2 else 0 for cat2 in categories] for cat1 in categories])

    # Combine all similarities with their respective weights
    combined_similarity = (
            text_weight * text_similarity +
            rating_weight * rating_similarity +
            price_weight * price_similarity +
            category_weight * category_similarity
    )

    return combined_similarity


# Load data

# courses_discount = pd.read_csv('drive/MyDrive/Data_PRSE/course_discount.csv')
# courses_category = pd.read_csv('drive/MyDrive/Data_PRSE/course_category.csv')
# # Select required columns
# courses = courses[['id', 'average_rating', 'description', 'original_price']]
# courses = courses.merge(courses_category[['course_id', 'sub_category_id']], left_on='id', right_on='course_id',
#                         how='left')

# Load PhoBERT model and tokenizer
model_name = 'vinai/phobert-base'
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModel.from_pretrained(model_name)


# Sá»­ dá»¥ng SQLAlchemy Ä‘á»ƒ dá»… dÃ ng chuyá»ƒn Ä‘á»•i sang DataFrame
def get_course():
    connection = mysql.connector.connect(
        host='14.225.253.200',  # IP address of your DB instance
        user='root',
        password='Hoanganh123!@#',
        database='prse'
    )
    cursor = connection.cursor()

    # Thay Ä‘á»•i cÃ¢u query theo cáº¥u trÃºc database cá»§a báº¡n
    query = """
      SELECT id, title, short_description, original_price
      FROM course
      WHERE is_publish = 1
  """

    cursor.execute(query)

    # Fetch all results
    data = cursor.fetchall()

    # Get column names
    columns = [desc[0] for desc in cursor.description]

    # Convert to DataFrame
    df = pd.DataFrame(data, columns=columns)

    # Print the DataFrame
    df['name'] = df['title']
    df['title'] = df['title'].str.lower() + ". " + df['short_description'].str.lower()
    return df

courses = get_course()
# Function to generate embeddings from PhoBERT
def generate_embedding(text):
    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)
    with torch.no_grad():
        outputs = model(**inputs)
    embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling
    return embeddings.squeeze().numpy()


# Function to find courses based on user input
def find_course(user_input, max_results=3):
    df = get_course()
    user_input = user_input.lower()
    user_input_embedding = generate_embedding(user_input)

    course_titles = df['title'].tolist()
    course_embeddings = np.array([generate_embedding(title) for title in course_titles])

    cosine_scores = np.dot(course_embeddings, user_input_embedding) / (
                np.linalg.norm(course_embeddings, axis=1) * np.linalg.norm(user_input_embedding))

    top_results = np.argsort(cosine_scores)[-max_results:][::-1]

    valid_results = [i for i in top_results if cosine_scores[i] >= 0.55]

    if not valid_results:
        return "KhÃ´ng tÃ¬m tháº¥y khÃ³a há»c phÃ¹ há»£p."
    else:
        # Retrieve courses that pass the cosine score threshold
        top_courses = df.iloc[valid_results]
        return top_courses


# Select required columns


# Calculate similarity matrix with effective prices
# similarity_matrix = calculate_combined_similarity(
#     courses,
#     courses_discount,
#     text_weight=0.75,
#     rating_weight=0.5,
#     price_weight=0.4
# )


# Assuming you have these loaded from somewhere
# You might want to load these when the application starts
def load_data():
    """
    Load the necessary data for recommendations
    You'll need to implement this based on how you store your data
    """
    global courses, similarity_matrix
    # Load your courses DataFrame
    # Load your similarity matrix
    pass


def get_top_rated_courses(n=10):
    """
    Get top N courses with highest ratings
    """
    try:
        # Sort by rating and get top N courses
        top_courses = courses.nlargest(n, 'average_rating')[['id', 'average_rating']]
        top_courses['based_on_courses'] = 'top_rated'  # Indicate these are top rated courses

        return top_courses
    except Exception as e:
        print(f"Error getting top rated courses: {e}")
        return None


@app.route('/api/recommend', methods=['POST'])
def get_recommendations():
    try:
        data = request.get_json()
        course_ids = data.get('course_ids', [])

        if not course_ids:
            top_rated = get_top_rated_courses(10)
            if top_rated is None:
                return jsonify({
                    'error': 'Could not fetch recommendations or top rated courses'
                }), 500

            result = top_rated.to_dict(orient='records')
            return jsonify({
                'status': 'success',
                'recommendations': result,
                'recommendation_type': 'top_rated'
            })

        # Get recommendations
        recommendations = get_similar_courses_combined(course_ids)

        if recommendations is None:
            # Get top rated courses instead
            top_rated = get_top_rated_courses(10)
            if top_rated is None:
                return jsonify({
                    'error': 'Could not fetch recommendations or top rated courses'
                }), 500

            result = top_rated.to_dict(orient='records')
            return jsonify({
                'status': 'success',
                'recommendations': result,
                'recommendation_type': 'top_rated'
            })

        # Convert DataFrame to dictionary for JSON response
        result = recommendations.to_dict(orient='records')

        return jsonify({
            'status': 'success',
            'recommendations': result,
            'recommendation_type': 'similar'
        })

    except Exception as e:
        return jsonify({
            'error': str(e)
        }), 500


def get_similar_courses_combined(course_ids, n=10):
    """
    Your existing recommendation function
    """
    try:
        # Get indices for all input course IDs
        indices = [courses.index[courses['id'] == cid][0] for cid in course_ids]

        # Extract vectors for each course
        course_vectors = similarity_matrix[indices]

        # Combine vectors by taking the mean
        combined_vector = np.mean(course_vectors, axis=0)

        # Calculate similarity between combined vector and all courses
        similarities = cosine_similarity([combined_vector], similarity_matrix)[0]

        # Get indices of top N similar courses
        # Exclude the input courses themselves
        mask = np.ones(len(similarities), dtype=bool)
        mask[indices] = False
        filtered_similarities = similarities * mask

        similar_indices = filtered_similarities.argsort()[::-1][:n]

        # Create DataFrame with similar courses
        similar_courses = courses.iloc[similar_indices][['id']]

        # Add original course IDs for reference

        return similar_courses

    except IndexError as e:
        print(f"Error: One or more course IDs not found in dataset")
        return None


# Add some error handlers
@app.errorhandler(404)
def not_found_error(error):
    return jsonify({
        'error': 'Resource not found'
    }), 404


@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'error': 'Internal server error'
    }), 500


# Add a health check endpoint
@app.route('/health', methods=['GET'])
def health_check():
    return jsonify({
        'status': 'healthy',
        'message': 'Service is running'
    })


@app.route('/rec_chatbot', methods=['POST'])
def find_courses():
    data = request.get_json()
    user_input = data.get('message', '')
    logger.info(f"=== New Request ===")
    logger.info(f"User input: {user_input}")
    # Validate input
    if not user_input:
        return jsonify({'error': 'No user input provided'}), 400

    matching_courses = find_course(user_input)

    if isinstance(matching_courses, pd.DataFrame) and not matching_courses.empty:
        
        footer_responses = [
            "ğŸŒŸ HÃ£y cÃ¹ng khÃ¡m phÃ¡ vÃ  báº¯t Ä‘áº§u hÃ nh trÃ¬nh há»c táº­p thÃº vá»‹ vá»›i EasyEdu nhÃ©!",
            "ğŸ“š ChÃºng ta hÃ£y bÆ°á»›c vÃ o tháº¿ giá»›i kiáº¿n thá»©c Ä‘áº§y mÃ u sáº¯c cÃ¹ng EasyEdu nÃ o!",
            "ğŸš€ Äá»«ng ngáº§n ngáº¡i, hÃ£y cÃ¹ng EasyEdu chinh phá»¥c nhá»¯ng Ä‘iá»u má»›i máº» nhÃ©!",
            "ğŸ¤ HÃ£y Ä‘á»ƒ EasyEdu Ä‘á»“ng hÃ nh cÃ¹ng báº¡n trong cuá»™c hÃ nh trÃ¬nh há»c táº­p tuyá»‡t vá»i nÃ y!",
            "ğŸŒˆ KhÃ¡m phÃ¡ nhá»¯ng Ä‘iá»u tuyá»‡t vá»i vÃ  báº¯t Ä‘áº§u há»c cÃ¹ng EasyEdu nÃ o!",
            "âœ¨ ChÃºng mÃ¬nh hÃ£y cÃ¹ng nhau khÃ¡m phÃ¡ hÃ nh trÃ¬nh há»c táº­p thÃº vá»‹ vá»›i EasyEdu nhÃ©!",
            "ğŸ“– HÃ£y tham gia cÃ¹ng EasyEdu Ä‘á»ƒ tráº£i nghiá»‡m nhá»¯ng bÃ i há»c bá»• Ã­ch nÃ o!",
            "ğŸŒŸ Khá»Ÿi Ä‘áº§u hÃ nh trÃ¬nh há»c táº­p cá»§a báº¡n vá»›i EasyEdu ngay hÃ´m nay!",
            "ğŸ’¡ HÃ£y Ä‘á»ƒ EasyEdu giÃºp báº¡n má»Ÿ rá»™ng kiáº¿n thá»©c vÃ  ká»¹ nÄƒng nhÃ©!",
            "ğŸ‰ ChÃºng ta hÃ£y cÃ¹ng nhau há»c há»i vÃ  phÃ¡t triá»ƒn vá»›i EasyEdu nÃ o!",
            "ğŸŒ HÃ£y khÃ¡m phÃ¡ tháº¿ giá»›i há»c táº­p rá»™ng lá»›n cÃ¹ng EasyEdu nhÃ©!",
            "ğŸŒ ChÃºng ta hÃ£y cÃ¹ng EasyEdu xÃ¢y dá»±ng tÆ°Æ¡ng lai tÆ°Æ¡i sÃ¡ng hÆ¡n!",
            "ğŸ“… HÃ£y báº¯t Ä‘áº§u hÃ nh trÃ¬nh há»c táº­p cá»§a báº¡n vá»›i nhá»¯ng khÃ³a há»c thÃº vá»‹ tá»« EasyEdu!",
            "ğŸˆ KhÃ¡m phÃ¡ vÃ  tráº£i nghiá»‡m nhá»¯ng Ä‘iá»u má»›i máº» cÃ¹ng EasyEdu nÃ o!",
            "ğŸ—ºï¸ HÃ£y Ä‘á»ƒ EasyEdu dáº«n dáº¯t báº¡n trÃªn con Ä‘Æ°á»ng tri thá»©c!",
            "ğŸ“ CÃ¹ng EasyEdu táº¡o nÃªn nhá»¯ng ká»· niá»‡m há»c táº­p Ä‘Ã¡ng nhá»› nhÃ©!",
            "ğŸ“ KhÃ¡m phÃ¡ nhá»¯ng khÃ³a há»c háº¥p dáº«n vÃ  thÃº vá»‹ vá»›i EasyEdu!",
            "ğŸ” HÃ£y tham gia cÃ¹ng EasyEdu Ä‘á»ƒ khÃ¡m phÃ¡ nhá»¯ng kiáº¿n thá»©c má»›i máº»!",
            "ğŸ† ChÃºng ta hÃ£y cÃ¹ng nhau vÆ°Æ¡n tá»›i nhá»¯ng Ä‘á»‰nh cao tri thá»©c cÃ¹ng EasyEdu!",
            "ğŸŒ¼ HÃ£y báº¯t tay vÃ o hÃ nh trÃ¬nh há»c táº­p Ä‘áº§y thÃº vá»‹ vá»›i EasyEdu nÃ o!"
        ]
        header_responses = [
            "ğŸŒŸ ChÃºng tÃ´i Ä‘Ã£ tÃ¬m tháº¥y nhá»¯ng khÃ³a há»c thÃº vá»‹ Ä‘ang chá» báº¡n! HÃ£y xem ngay nhÃ©:",
            "ğŸ‰ Trá»£ lÃ½ EasyEdu Ä‘Ã£ phÃ¡t hiá»‡n ra cÃ¡c khÃ³a há»c Ä‘á»™c Ä‘Ã¡o dÃ nh cho báº¡n. HÃ£y cÃ¹ng khÃ¡m phÃ¡ nÃ o:",
            "ğŸ“š Trá»£ lÃ½ EasyEdu ráº¥t vui khi tÃ¬m tháº¥y cÃ¡c khÃ³a há»c phÃ¹ há»£p vá»›i báº¡n! HÃ£y thá»­ ngay nhÃ©:",
            "âœ¨ Wow! Nhá»¯ng khÃ³a há»c tuyá»‡t vá»i Ä‘Ã£ sáºµn sÃ ng cho báº¡n. HÃ£y xem ngay nÃ o:",
            "ğŸš€ Trá»£ lÃ½ EasyEdu Ä‘Ã£ tÃ¬m ra cÃ¡c khÃ³a há»c phÃ¹ há»£p vá»›i sá»Ÿ thÃ­ch cá»§a báº¡n. HÃ£y khÃ¡m phÃ¡ nhÃ©:",
            "ğŸŒ¼ Trá»£ lÃ½ EasyEdu ráº¥t vui thÃ´ng bÃ¡o ráº±ng Ä‘Ã£ cÃ³ nhá»¯ng khÃ³a há»c tuyá»‡t vá»i cho báº¡n. HÃ£y xem ngay:",
            "ğŸˆ Hooray! CÃ¡c khÃ³a há»c lÃ½ tÆ°á»Ÿng Ä‘ang chá» Ä‘Ã³n báº¡n. HÃ£y tÃ¬m hiá»ƒu ngay nhÃ©:",
            "ğŸ˜ Trá»£ lÃ½ EasyEdu Ä‘Ã£ phÃ¡t hiá»‡n ra nhá»¯ng khÃ³a há»c Ä‘áº·c biá»‡t dÃ nh cho báº¡n. HÃ£y cÃ¹ng xem nÃ o:",
            "ğŸ’– Nhá»¯ng khÃ³a há»c phÃ¹ há»£p Ä‘Ã£ Ä‘Æ°á»£c tÃ¬m tháº¥y! HÃ£y khÃ¡m phÃ¡ cÃ¹ng trá»£ lÃ½ EasyEdu nhÃ©:",
            "ğŸŒˆ Trá»£ lÃ½ EasyEdu ráº¥t vui khi thÃ´ng bÃ¡o ráº±ng Ä‘Ã£ cÃ³ cÃ¡c khÃ³a há»c phÃ¹ há»£p vá»›i báº¡n. HÃ£y xem ngay:",
            "ğŸ¥³ Trá»£ lÃ½ EasyEdu Ä‘Ã£ tÃ¬m tháº¥y nhá»¯ng khÃ³a há»c thÃº vá»‹ dÃ nh cho báº¡n. HÃ£y cÃ¹ng khÃ¡m phÃ¡ nhÃ©:",
            "ğŸŒŸ Tá»‘t quÃ¡! Trá»£ lÃ½ EasyEdu Ä‘Ã£ phÃ¡t hiá»‡n ra cÃ¡c khÃ³a há»c tuyá»‡t vá»i cho báº¡n. HÃ£y xem ngay:",
            "ğŸ‰ Nhá»¯ng khÃ³a há»c phÃ¹ há»£p vá»›i báº¡n Ä‘Ã£ Ä‘Æ°á»£c tÃ¬m tháº¥y! HÃ£y khÃ¡m phÃ¡ ngay nhÃ©:",
            "ğŸ“š Trá»£ lÃ½ EasyEdu ráº¥t vui khi thÃ´ng bÃ¡o ráº±ng Ä‘Ã£ cÃ³ cÃ¡c khÃ³a há»c phÃ¹ há»£p vá»›i báº¡n. HÃ£y xem ngay:",
            "ğŸš€ CÃ¡c khÃ³a há»c lÃ½ tÆ°á»Ÿng Ä‘ang chá» báº¡n! HÃ£y cÃ¹ng khÃ¡m phÃ¡ nhÃ©:",
            "âœ¨ Trá»£ lÃ½ EasyEdu Ä‘Ã£ tÃ¬m tháº¥y nhá»¯ng khÃ³a há»c tuyá»‡t vá»i cho báº¡n. HÃ£y xem ngay nÃ o:",
            "ğŸŒ¼ Hooray! Nhá»¯ng khÃ³a há»c phÃ¹ há»£p Ä‘Ã£ sáºµn sÃ ng cho báº¡n. HÃ£y khÃ¡m phÃ¡ ngay nhÃ©:",
            "ğŸˆ Trá»£ lÃ½ EasyEdu ráº¥t vui khi tÃ¬m tháº¥y cÃ¡c khÃ³a há»c thÃº vá»‹ cho báº¡n. HÃ£y cÃ¹ng xem nÃ o:",
            "ğŸ˜ Trá»£ lÃ½ EasyEdu Ä‘Ã£ phÃ¡t hiá»‡n ra nhá»¯ng khÃ³a há»c tuyá»‡t vá»i dÃ nh cho báº¡n. HÃ£y khÃ¡m phÃ¡ ngay nhÃ©:",
            "ğŸ’– Nhá»¯ng khÃ³a há»c phÃ¹ há»£p vá»›i báº¡n Ä‘Ã£ sáºµn sÃ ng! HÃ£y cÃ¹ng khÃ¡m phÃ¡ vá»›i trá»£ lÃ½ EasyEdu nhÃ©:"
        ]
        random_header = random.choice(header_responses)
        random_footer = random.choice(footer_responses)
        course_list = []
        count = 0
        for index, course_info in matching_courses.iterrows():
            course_name = course_info['name']
            course_link = 'https://prse-fe.vercel.app/course-detail/' + str(course_info['id'])
            course_price = course_info['original_price']
            course_price = format_price(course_price)

            # Â· GiÃ¡ :
            # Â· Link :

            course_list.append(
                f"**{count + 1}. {course_name}**:" + "\n " + f"Â· **GiÃ¡ :** {course_price} VND" + "\n" + f"Â· **Link :** {course_link}")
            count += 1
        all_courses = f"{random_header}\n" + "\n".join(course_list) + f"\n{random_footer}"
        return jsonify({'error_message': {},
                        'code': 1,
                        'data': {
                            'message': all_courses
                        }}), 200

    else:
        no_responses = [
            "ğŸŒ¼ Ã”i khÃ´ng! Trá»£ lÃ½ EasyEdu khÃ´ng tÃ¬m tháº¥y khÃ³a há»c nÃ o phÃ¹ há»£p vá»›i báº¡n. HÃ£y thá»­ láº¡i láº§n ná»¯a nhÃ©, cÃ³ thá»ƒ Ä‘iá»u gÃ¬ Ä‘Ã³ tuyá»‡t vá»i sáº½ xuáº¥t hiá»‡n!",
            "ğŸ¤— Trá»£ lÃ½ EasyEdu ráº¥t tiáº¿c, nhÆ°ng hiá»‡n táº¡i chÆ°a tÃ¬m tháº¥y khÃ³a há»c nÃ o há»£p vá»›i báº¡n. Äá»«ng ngáº¡i thá»­ láº¡i sau má»™t chÃºt nhÃ©!",
            "ğŸ’” Ráº¥t tiáº¿c, nhÆ°ng cÃ³ váº» nhÆ° trá»£ lÃ½ EasyEdu chÆ°a tÃ¬m tháº¥y khÃ³a há»c nÃ o phÃ¹ há»£p. HÃ£y thá»­ láº¡i láº§n ná»¯a, cÃ³ thá»ƒ báº¡n sáº½ tÃ¬m tháº¥y Ä‘iá»u mÃ¬nh thÃ­ch!",
            "ğŸŒŸ DÃ¹ trá»£ lÃ½ EasyEdu chÆ°a tÃ¬m tháº¥y khÃ³a há»c nÃ o phÃ¹ há»£p, hÃ£y thá»­ láº¡i nhÃ©! CÃ³ thá»ƒ Ä‘iá»u báº¥t ngá» Ä‘ang chá» báº¡n á»Ÿ láº§n sau!",
            "âœ¨ Trá»£ lÃ½ EasyEdu khÃ´ng tÃ¬m tháº¥y khÃ³a há»c nÃ o phÃ¹ há»£p vá»›i báº¡n. NhÆ°ng Ä‘á»«ng náº£n lÃ²ng, hÃ£y thá»­ láº¡i láº§n ná»¯a nhÃ©!",
            "ğŸŒˆ Trá»£ lÃ½ EasyEdu muá»‘n giÃºp báº¡n, nhÆ°ng hiá»‡n táº¡i chÆ°a cÃ³ khÃ³a há»c nÃ o phÃ¹ há»£p. HÃ£y quay láº¡i vÃ  thá»­ láº¡i má»™t láº§n ná»¯a nhÃ©!",
            "ğŸ¤” CÃ³ váº» nhÆ° trá»£ lÃ½ EasyEdu chÆ°a tÃ¬m tháº¥y khÃ³a há»c nÃ o há»£p vá»›i báº¡n. HÃ£y thá»­ láº¡i sau má»™t chÃºt, biáº¿t Ä‘Ã¢u sáº½ cÃ³ Ä‘iá»u thÃº vá»‹!",
            "ğŸŒ» Äá»«ng buá»“n nhÃ©! Hiá»‡n táº¡i trá»£ lÃ½ EasyEdu chÆ°a tÃ¬m tháº¥y khÃ³a há»c nÃ o phÃ¹ há»£p, nhÆ°ng hÃ£y thá»­ láº¡i láº§n ná»¯a Ä‘á»ƒ tÃ¬m kiáº¿m thÃªm lá»±a chá»n!",
            "ğŸ’– Ráº¥t tiáº¿c vÃ¬ trá»£ lÃ½ EasyEdu chÆ°a tÃ¬m tháº¥y khÃ³a há»c nÃ o cho báº¡n. HÃ£y ghÃ© thÄƒm thÆ°á»ng xuyÃªn vÃ  thá»­ láº¡i láº§n ná»¯a nhÃ©!",
            "ğŸ¾ Máº·c dÃ¹ trá»£ lÃ½ EasyEdu chÆ°a tÃ¬m tháº¥y khÃ³a há»c nÃ o phÃ¹ há»£p, nhÆ°ng hÃ£y kiÃªn nháº«n vÃ  thá»­ láº¡i sau. Trá»£ lÃ½ EasyEdu luÃ´n á»Ÿ Ä‘Ã¢y Ä‘á»ƒ há»— trá»£ báº¡n!"
        ]
        all_courses = random.choice(no_responses)
        return jsonify({'error_message': {},
                        'code': 1,
                        'data': {
                            'message': all_courses
                        }}), 200


if __name__ == '__main__':
    # Load the data when the application starts
    load_data()
    port = int(os.environ.get('PORT', 5000))
    print("Starting production server...")
    # app.run(debug=True, host='0.0.0.0', port=port)
    serve(app, host='0.0.0.0', port=port)
