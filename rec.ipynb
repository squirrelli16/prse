{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/squirrelli16/prse/blob/main/rec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0aUfrF-wIC8w",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aUfrF-wIC8w",
        "outputId": "69fb4cff-d127-4fa2-9271-606c836bdf2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask_cors in /usr/local/lib/python3.10/dist-packages (5.0.0)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask_cors) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask_cors) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->Flask>=0.9->flask_cors) (3.0.2)\n",
            "Requirement already satisfied: underthesea in /usr/local/lib/python3.10/dist-packages (6.8.4)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from underthesea) (8.1.7)\n",
            "Requirement already satisfied: python-crfsuite>=0.9.6 in /usr/local/lib/python3.10/dist-packages (from underthesea) (0.9.11)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from underthesea) (3.9.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from underthesea) (4.66.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from underthesea) (2.32.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.5.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from underthesea) (6.0.2)\n",
            "Requirement already satisfied: underthesea-core==1.0.4 in /usr/local/lib/python3.10/dist-packages (from underthesea) (1.0.4)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->underthesea) (2024.9.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->underthesea) (2024.8.30)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (1.13.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->underthesea) (3.5.0)\n",
            "Requirement already satisfied: waitress in /usr/local/lib/python3.10/dist-packages (3.0.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.11.9)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.8.30)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->openai==0.28) (4.12.2)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (3.2.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.46.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.6)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.5.1+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.26.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (11.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.8.30)\n",
            "Collecting mysql-connector-python\n",
            "  Downloading mysql_connector_python-9.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
            "Downloading mysql_connector_python-9.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mysql-connector-python\n",
            "Successfully installed mysql-connector-python-9.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install flask_cors\n",
        "!pip install underthesea\n",
        "!pip install waitress\n",
        "!pip install pyngrok\n",
        "!pip install openai==0.28\n",
        "!pip install sentence-transformers\n",
        "!pip install mysql-connector-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YKJ4oG-WHkeK",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKJ4oG-WHkeK",
        "outputId": "89dcf835-aa0e-4df0-ae19-4d753591ec1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "13b03f9e38ff0e2f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13b03f9e38ff0e2f",
        "outputId": "b88734fb-46c1-4541-da49-82e8457262d6"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Flask app is available at: https://ad62-34-19-104-54.ngrok-free.app\n",
            "API_site: https://ad62-34-19-104-54.ngrok-free.app\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5000\n",
            " * Running on http://172.28.0.12:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Dec/2024 13:33:33] \"POST /rec_chatbot HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Dec/2024 13:33:45] \"\u001b[33mGET /robots.txt HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Dec/2024 13:33:45] \"\u001b[31m\u001b[1mGET /rec_chatbot HTTP/1.1\u001b[0m\" 405 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Dec/2024 13:34:14] \"OPTIONS /rec_chatbot HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Dec/2024 13:34:37] \"POST /rec_chatbot HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Dec/2024 13:34:51] \"OPTIONS /rec_chatbot HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Dec/2024 13:35:21] \"POST /rec_chatbot HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Dec/2024 13:38:28] \"OPTIONS /rec_chatbot HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [07/Dec/2024 13:38:54] \"POST /rec_chatbot HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from underthesea import word_tokenize\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from waitress import serve\n",
        "from pyngrok import ngrok, conf\n",
        "from google.colab import userdata\n",
        "import pandas as pd\n",
        "import openai\n",
        "import torch\n",
        "from google.colab import userdata\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import mysql.connector\n",
        "import numpy as np\n",
        "import random\n",
        "app = Flask(__name__)\n",
        "conf.get_default().auth_token = userdata.get('Ngrok')\n",
        "ngrok.set_auth_token('Ngrok')  # Ensure you have the correct token\n",
        "ngrok.kill()\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f'Flask app is available at: {public_url}')\n",
        "CORS(app)\n",
        "def preprocess_vietnamese(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    return ' '.join(tokens)\n",
        "def format_price(price):\n",
        "    return \"{:,.0f}\".format(price).replace(',', '.')\n",
        "\n",
        "def get_effective_price(row, courses_discount):\n",
        "    \"\"\"\n",
        "    Get the effective price considering discounts\n",
        "    \"\"\"\n",
        "    course_id = row['id']\n",
        "    original_price = row['original_price']\n",
        "\n",
        "    # Check if course has an active discount\n",
        "    discount_info = courses_discount[\n",
        "        (courses_discount['course_id'] == course_id) &\n",
        "        (courses_discount['is_active'] == True)\n",
        "    ]\n",
        "\n",
        "    if not discount_info.empty:\n",
        "        return discount_info.iloc[0]['discount_price']\n",
        "    return original_price\n",
        "\n",
        "def calculate_combined_similarity(courses, courses_discount, text_weight=0.6, rating_weight=0.2, price_weight=0.2, category_weight=0.9):\n",
        "    \"\"\"\n",
        "    Calculate similarity between courses based on description, rating, and effective price\n",
        "\n",
        "    Parameters:\n",
        "    - courses: DataFrame containing 'id', 'description', 'average_rating', and 'original_price'\n",
        "    - courses_discount: DataFrame containing discount information\n",
        "    - text_weight: weight for description similarity (default: 0.6)\n",
        "    - rating_weight: weight for rating similarity (default: 0.2)\n",
        "    - price_weight: weight for price similarity (default: 0.2)\n",
        "\n",
        "    Returns:\n",
        "    - combined similarity matrix\n",
        "    \"\"\"\n",
        "    # Preprocess description\n",
        "    courses['description'] = courses['description'].apply(preprocess_vietnamese)\n",
        "\n",
        "    # Calculate text similarity\n",
        "    tfidf = TfidfVectorizer(\n",
        "        max_features=3522,\n",
        "        ngram_range=(1, 2)\n",
        "    )\n",
        "    text_vectors = tfidf.fit_transform(courses['description'])\n",
        "    text_similarity = cosine_similarity(text_vectors)\n",
        "\n",
        "    # Calculate effective prices considering discounts\n",
        "    courses['effective_price'] = courses.apply(\n",
        "        lambda row: get_effective_price(row, courses_discount),\n",
        "        axis=1\n",
        "    )\n",
        "    # Normalize numerical features\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Handle rating similarity\n",
        "    ratings = courses[['average_rating']].values\n",
        "    normalized_ratings = scaler.fit_transform(ratings)\n",
        "    rating_similarity = 1 - np.abs(normalized_ratings - normalized_ratings.T)\n",
        "\n",
        "    # Handle price similarity using effective prices\n",
        "    prices = courses[['effective_price']].values\n",
        "    normalized_prices = scaler.fit_transform(prices)\n",
        "    price_similarity = 1 - np.abs(normalized_prices - normalized_prices.T)\n",
        "\n",
        "    # Handle category similarity: 1 if categories match, 0 if they don't\n",
        "    categories = courses[['sub_category_id']].values\n",
        "    category_similarity = np.array([[1 if cat1 == cat2 else 0 for cat2 in categories] for cat1 in categories])\n",
        "\n",
        "    # Combine all similarities with their respective weights\n",
        "    combined_similarity = (\n",
        "        text_weight * text_similarity +\n",
        "        rating_weight * rating_similarity +\n",
        "        price_weight * price_similarity +\n",
        "        category_weight * category_similarity\n",
        "    )\n",
        "\n",
        "    return combined_similarity\n",
        "\n",
        "# Load data\n",
        "courses = pd.read_csv('drive/MyDrive/Data_PRSE/course.csv')\n",
        "courses_discount = pd.read_csv('drive/MyDrive/Data_PRSE/course_discount.csv')\n",
        "courses_category = pd.read_csv('drive/MyDrive/Data_PRSE/course_category.csv')\n",
        "\n",
        "\n",
        "# Load PhoBERT model and tokenizer\n",
        "model_name = 'vinai/phobert-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# Sử dụng SQLAlchemy để dễ dàng chuyển đổi sang DataFrame\n",
        "connection = mysql.connector.connect(\n",
        "    host='14.225.253.200',       # IP address of your DB instance\n",
        "    user='root',\n",
        "    password='Hoanganh123!@#',\n",
        "    database='prse'\n",
        ")\n",
        "cursor = connection.cursor()\n",
        "\n",
        "# Thay đổi câu query theo cấu trúc database của bạn\n",
        "query = \"\"\"\n",
        "    SELECT id, title, description, original_price\n",
        "    FROM course\n",
        "    WHERE is_publish = 1\n",
        "\"\"\"\n",
        "\n",
        "cursor.execute(query)\n",
        "\n",
        "# Fetch all results\n",
        "data = cursor.fetchall()\n",
        "\n",
        "# Get column names\n",
        "columns = [desc[0] for desc in cursor.description]\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "\n",
        "# Print the DataFrame\n",
        "df['name']= df['title']\n",
        "df['title'] = df['title'].str.lower() + \". \" + df['description'].str.lower()\n",
        "# Function to generate embeddings from PhoBERT\n",
        "def generate_embedding(text):\n",
        "    inputs = tokenizer(text, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    embeddings = outputs.last_hidden_state.mean(dim=1)  # Mean pooling\n",
        "    return embeddings.squeeze().numpy()\n",
        "\n",
        "# Function to find courses based on user input\n",
        "def find_course(user_input, max_results=3):\n",
        "    user_input= user_input.lower()\n",
        "    user_input_embedding = generate_embedding(user_input)\n",
        "\n",
        "    course_titles = df['title'].tolist()\n",
        "    course_embeddings = np.array([generate_embedding(title) for title in course_titles])\n",
        "\n",
        "    cosine_scores = np.dot(course_embeddings, user_input_embedding) / (np.linalg.norm(course_embeddings, axis=1) * np.linalg.norm(user_input_embedding))\n",
        "\n",
        "    top_results = np.argsort(cosine_scores)[-max_results:][::-1]\n",
        "\n",
        "    valid_results = [i for i in top_results if cosine_scores[i] >= 0.55]\n",
        "\n",
        "    if not valid_results:\n",
        "        return \"Không tìm thấy khóa học phù hợp.\"\n",
        "    else:\n",
        "        # Retrieve courses that pass the cosine score threshold\n",
        "        top_courses = df.iloc[valid_results]\n",
        "        return top_courses\n",
        "# Select required columns\n",
        "courses = courses[['id', 'average_rating', 'description', 'original_price']]\n",
        "courses = courses.merge(courses_category[['course_id', 'sub_category_id']], left_on='id', right_on='course_id', how='left')\n",
        "\n",
        "# Calculate similarity matrix with effective prices\n",
        "similarity_matrix = calculate_combined_similarity(\n",
        "    courses,\n",
        "    courses_discount,\n",
        "    text_weight=0.75,\n",
        "    rating_weight=0.5,\n",
        "    price_weight=0.4\n",
        ")\n",
        "# Assuming you have these loaded from somewhere\n",
        "# You might want to load these when the application starts\n",
        "def load_data():\n",
        "    \"\"\"\n",
        "    Load the necessary data for recommendations\n",
        "    You'll need to implement this based on how you store your data\n",
        "    \"\"\"\n",
        "    global courses, similarity_matrix\n",
        "    # Load your courses DataFrame\n",
        "    # Load your similarity matrix\n",
        "    pass\n",
        "def get_top_rated_courses(n=10):\n",
        "    \"\"\"\n",
        "    Get top N courses with highest ratings\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Sort by rating and get top N courses\n",
        "        top_courses = courses.nlargest(n, 'average_rating')[['id', 'average_rating']]\n",
        "        top_courses['based_on_courses'] = 'top_rated'  # Indicate these are top rated courses\n",
        "\n",
        "        return top_courses\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting top rated courses: {e}\")\n",
        "        return None\n",
        "\n",
        "@app.route('/api/recommend', methods=['POST'])\n",
        "def get_recommendations():\n",
        "    try:\n",
        "        data = request.get_json()\n",
        "        course_ids = data.get('course_ids', [])\n",
        "\n",
        "        if not course_ids:\n",
        "            top_rated = get_top_rated_courses(10)\n",
        "            if top_rated is None:\n",
        "                return jsonify({\n",
        "                    'error': 'Could not fetch recommendations or top rated courses'\n",
        "                }), 500\n",
        "\n",
        "            result = top_rated.to_dict(orient='records')\n",
        "            return jsonify({\n",
        "                'status': 'success',\n",
        "                'recommendations': result,\n",
        "                'recommendation_type': 'top_rated'\n",
        "            })\n",
        "\n",
        "        # Get recommendations\n",
        "        recommendations = get_similar_courses_combined(course_ids)\n",
        "\n",
        "        if recommendations is None:\n",
        "            # Get top rated courses instead\n",
        "            top_rated = get_top_rated_courses(10)\n",
        "            if top_rated is None:\n",
        "                return jsonify({\n",
        "                    'error': 'Could not fetch recommendations or top rated courses'\n",
        "                }), 500\n",
        "\n",
        "            result = top_rated.to_dict(orient='records')\n",
        "            return jsonify({\n",
        "                'status': 'success',\n",
        "                'recommendations': result,\n",
        "                'recommendation_type': 'top_rated'\n",
        "            })\n",
        "\n",
        "        # Convert DataFrame to dictionary for JSON response\n",
        "        result = recommendations.to_dict(orient='records')\n",
        "\n",
        "        return jsonify({\n",
        "            'status': 'success',\n",
        "            'recommendations': result,\n",
        "            'recommendation_type': 'similar'\n",
        "        })\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({\n",
        "            'error': str(e)\n",
        "        }), 500\n",
        "\n",
        "\n",
        "def get_similar_courses_combined(course_ids, n=10):\n",
        "    \"\"\"\n",
        "    Your existing recommendation function\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Get indices for all input course IDs\n",
        "        indices = [courses.index[courses['id'] == cid][0] for cid in course_ids]\n",
        "\n",
        "        # Extract vectors for each course\n",
        "        course_vectors = similarity_matrix[indices]\n",
        "\n",
        "        # Combine vectors by taking the mean\n",
        "        combined_vector = np.mean(course_vectors, axis=0)\n",
        "\n",
        "        # Calculate similarity between combined vector and all courses\n",
        "        similarities = cosine_similarity([combined_vector], similarity_matrix)[0]\n",
        "\n",
        "        # Get indices of top N similar courses\n",
        "        # Exclude the input courses themselves\n",
        "        mask = np.ones(len(similarities), dtype=bool)\n",
        "        mask[indices] = False\n",
        "        filtered_similarities = similarities * mask\n",
        "\n",
        "        similar_indices = filtered_similarities.argsort()[::-1][:n]\n",
        "\n",
        "        # Create DataFrame with similar courses\n",
        "        similar_courses = courses.iloc[similar_indices][['id']]\n",
        "\n",
        "        # Add original course IDs for reference\n",
        "\n",
        "        return similar_courses\n",
        "\n",
        "    except IndexError as e:\n",
        "        print(f\"Error: One or more course IDs not found in dataset\")\n",
        "        return None\n",
        "\n",
        "# Add some error handlers\n",
        "@app.errorhandler(404)\n",
        "def not_found_error(error):\n",
        "    return jsonify({\n",
        "        'error': 'Resource not found'\n",
        "    }), 404\n",
        "\n",
        "@app.errorhandler(500)\n",
        "def internal_error(error):\n",
        "    return jsonify({\n",
        "        'error': 'Internal server error'\n",
        "    }), 500\n",
        "\n",
        "# Add a health check endpoint\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health_check():\n",
        "    return jsonify({\n",
        "        'status': 'healthy',\n",
        "        'message': 'Service is running'\n",
        "    })\n",
        "@app.route('/rec_chatbot', methods=['POST'])\n",
        "def find_courses():\n",
        "    data = request.get_json()\n",
        "    user_input = data.get('message', '')\n",
        "\n",
        "    # Validate input\n",
        "    if not user_input:\n",
        "        return jsonify({'error': 'No user input provided'}), 400\n",
        "\n",
        "    matching_courses = find_course(user_input)\n",
        "\n",
        "    if isinstance(matching_courses, pd.DataFrame) and not matching_courses.empty:\n",
        "        openai.api_key = userdata.get('GPT') # Replace with your OpenAI API Key\n",
        "        footer_responses = [\n",
        "            \"🌟 Hãy cùng khám phá và bắt đầu hành trình học tập thú vị với EasyEdu nhé!\",\n",
        "            \"📚 Chúng ta hãy bước vào thế giới kiến thức đầy màu sắc cùng EasyEdu nào!\",\n",
        "            \"🚀 Đừng ngần ngại, hãy cùng EasyEdu chinh phục những điều mới mẻ nhé!\",\n",
        "            \"🤝 Hãy để EasyEdu đồng hành cùng bạn trong cuộc hành trình học tập tuyệt vời này!\",\n",
        "            \"🌈 Khám phá những điều tuyệt vời và bắt đầu học cùng EasyEdu nào!\",\n",
        "            \"✨ Chúng mình hãy cùng nhau khám phá hành trình học tập thú vị với EasyEdu nhé!\",\n",
        "            \"📖 Hãy tham gia cùng EasyEdu để trải nghiệm những bài học bổ ích nào!\",\n",
        "            \"🌟 Khởi đầu hành trình học tập của bạn với EasyEdu ngay hôm nay!\",\n",
        "            \"💡 Hãy để EasyEdu giúp bạn mở rộng kiến thức và kỹ năng nhé!\",\n",
        "            \"🎉 Chúng ta hãy cùng nhau học hỏi và phát triển với EasyEdu nào!\",\n",
        "            \"🌍 Hãy khám phá thế giới học tập rộng lớn cùng EasyEdu nhé!\",\n",
        "            \"🌞 Chúng ta hãy cùng EasyEdu xây dựng tương lai tươi sáng hơn!\",\n",
        "            \"📅 Hãy bắt đầu hành trình học tập của bạn với những khóa học thú vị từ EasyEdu!\",\n",
        "            \"🎈 Khám phá và trải nghiệm những điều mới mẻ cùng EasyEdu nào!\",\n",
        "            \"🗺️ Hãy để EasyEdu dẫn dắt bạn trên con đường tri thức!\",\n",
        "            \"🎓 Cùng EasyEdu tạo nên những kỷ niệm học tập đáng nhớ nhé!\",\n",
        "            \"📝 Khám phá những khóa học hấp dẫn và thú vị với EasyEdu!\",\n",
        "            \"🔍 Hãy tham gia cùng EasyEdu để khám phá những kiến thức mới mẻ!\",\n",
        "            \"🏆 Chúng ta hãy cùng nhau vươn tới những đỉnh cao tri thức cùng EasyEdu!\",\n",
        "            \"🌼 Hãy bắt tay vào hành trình học tập đầy thú vị với EasyEdu nào!\"\n",
        "        ]\n",
        "        header_responses = [\n",
        "            \"🌟 Chúng tôi đã tìm thấy những khóa học thú vị đang chờ bạn! Hãy xem ngay nhé:\",\n",
        "            \"🎉 Trợ lý EasyEdu đã phát hiện ra các khóa học độc đáo dành cho bạn. Hãy cùng khám phá nào:\",\n",
        "            \"📚 Trợ lý EasyEdu rất vui khi tìm thấy các khóa học phù hợp với bạn! Hãy thử ngay nhé:\",\n",
        "            \"✨ Wow! Những khóa học tuyệt vời đã sẵn sàng cho bạn. Hãy xem ngay nào:\",\n",
        "            \"🚀 Trợ lý EasyEdu đã tìm ra các khóa học phù hợp với sở thích của bạn. Hãy khám phá nhé:\",\n",
        "            \"🌼 Trợ lý EasyEdu rất vui thông báo rằng đã có những khóa học tuyệt vời cho bạn. Hãy xem ngay:\",\n",
        "            \"🎈 Hooray! Các khóa học lý tưởng đang chờ đón bạn. Hãy tìm hiểu ngay nhé:\",\n",
        "            \"😍 Trợ lý EasyEdu đã phát hiện ra những khóa học đặc biệt dành cho bạn. Hãy cùng xem nào:\",\n",
        "            \"💖 Những khóa học phù hợp đã được tìm thấy! Hãy khám phá cùng trợ lý EasyEdu nhé:\",\n",
        "            \"🌈 Trợ lý EasyEdu rất vui khi thông báo rằng đã có các khóa học phù hợp với bạn. Hãy xem ngay:\",\n",
        "            \"🥳 Trợ lý EasyEdu đã tìm thấy những khóa học thú vị dành cho bạn. Hãy cùng khám phá nhé:\",\n",
        "            \"🌟 Tốt quá! Trợ lý EasyEdu đã phát hiện ra các khóa học tuyệt vời cho bạn. Hãy xem ngay:\",\n",
        "            \"🎉 Những khóa học phù hợp với bạn đã được tìm thấy! Hãy khám phá ngay nhé:\",\n",
        "            \"📚 Trợ lý EasyEdu rất vui khi thông báo rằng đã có các khóa học phù hợp với bạn. Hãy xem ngay:\",\n",
        "            \"🚀 Các khóa học lý tưởng đang chờ bạn! Hãy cùng khám phá nhé:\",\n",
        "            \"✨ Trợ lý EasyEdu đã tìm thấy những khóa học tuyệt vời cho bạn. Hãy xem ngay nào:\",\n",
        "            \"🌼 Hooray! Những khóa học phù hợp đã sẵn sàng cho bạn. Hãy khám phá ngay nhé:\",\n",
        "            \"🎈 Trợ lý EasyEdu rất vui khi tìm thấy các khóa học thú vị cho bạn. Hãy cùng xem nào:\",\n",
        "            \"😍 Trợ lý EasyEdu đã phát hiện ra những khóa học tuyệt vời dành cho bạn. Hãy khám phá ngay nhé:\",\n",
        "            \"💖 Những khóa học phù hợp với bạn đã sẵn sàng! Hãy cùng khám phá với trợ lý EasyEdu nhé:\"\n",
        "        ]\n",
        "        random_header = random.choice(header_responses)\n",
        "        random_footer = random.choice(footer_responses)\n",
        "        course_list = []\n",
        "        count=0\n",
        "        for index, course_info in matching_courses.iterrows():\n",
        "            course_name = course_info['name']\n",
        "            course_link = 'https://prse-fe.vercel.app/course-detail/' + str(course_info['id'])\n",
        "            course_price = course_info['original_price']\n",
        "            course_price= format_price(course_price)\n",
        "\n",
        "# · Giá :\n",
        "# · Link :\n",
        "\n",
        "            course_list.append(f\"**{count + 1}. {course_name}**:\"+\"\\n \"+ f\"· **Giá :** {course_price} VND\"+\"\\n\"+ f\"· **Link :** {course_link}\")\n",
        "            count+=1\n",
        "        all_courses = f\"{random_header}\\n\" + \"\\n\".join(course_list) + f\"\\n{random_footer}\"\n",
        "        return jsonify({'error_message': {},\n",
        "                'code': 1,\n",
        "                'data':{\n",
        "                  'message': all_courses\n",
        "                }}), 200\n",
        "\n",
        "    else:\n",
        "        no_responses = [\n",
        "            \"🌼 Ôi không! Trợ lý EasyEdu không tìm thấy khóa học nào phù hợp với bạn. Hãy thử lại lần nữa nhé, có thể điều gì đó tuyệt vời sẽ xuất hiện!\",\n",
        "            \"🤗 Trợ lý EasyEdu rất tiếc, nhưng hiện tại chưa tìm thấy khóa học nào hợp với bạn. Đừng ngại thử lại sau một chút nhé!\",\n",
        "            \"💔 Rất tiếc, nhưng có vẻ như trợ lý EasyEdu chưa tìm thấy khóa học nào phù hợp. Hãy thử lại lần nữa, có thể bạn sẽ tìm thấy điều mình thích!\",\n",
        "            \"🌟 Dù trợ lý EasyEdu chưa tìm thấy khóa học nào phù hợp, hãy thử lại nhé! Có thể điều bất ngờ đang chờ bạn ở lần sau!\",\n",
        "            \"✨ Trợ lý EasyEdu không tìm thấy khóa học nào phù hợp với bạn. Nhưng đừng nản lòng, hãy thử lại lần nữa nhé!\",\n",
        "            \"🌈 Trợ lý EasyEdu muốn giúp bạn, nhưng hiện tại chưa có khóa học nào phù hợp. Hãy quay lại và thử lại một lần nữa nhé!\",\n",
        "            \"🤔 Có vẻ như trợ lý EasyEdu chưa tìm thấy khóa học nào hợp với bạn. Hãy thử lại sau một chút, biết đâu sẽ có điều thú vị!\",\n",
        "            \"🌻 Đừng buồn nhé! Hiện tại trợ lý EasyEdu chưa tìm thấy khóa học nào phù hợp, nhưng hãy thử lại lần nữa để tìm kiếm thêm lựa chọn!\",\n",
        "            \"💖 Rất tiếc vì trợ lý EasyEdu chưa tìm thấy khóa học nào cho bạn. Hãy ghé thăm thường xuyên và thử lại lần nữa nhé!\",\n",
        "            \"🐾 Mặc dù trợ lý EasyEdu chưa tìm thấy khóa học nào phù hợp, nhưng hãy kiên nhẫn và thử lại sau. Trợ lý EasyEdu luôn ở đây để hỗ trợ bạn!\"\n",
        "        ]\n",
        "        all_courses = random.choice(no_responses)\n",
        "        return jsonify({'error_message': {},\n",
        "                'code': 1,\n",
        "                'data':{\n",
        "                  'message': all_courses\n",
        "                }}), 200\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Load the data when the application starts\n",
        "    load_data()\n",
        "    print(\"API_site:\",public_url)\n",
        "    app.run(debug=False, host='0.0.0.0', port=5000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d97cee155f9547c9",
      "metadata": {
        "id": "d97cee155f9547c9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "initial_id",
        "outputId": "d710e529-1daa-4c1f-f969-3e512c2b8207"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    id  average_rating                                        description  \\\n",
            "0    1             5.0                              Kiến thức nhập môn IT   \n",
            "1    2             4.0                              Kiến thức nhập môn IT   \n",
            "2    2             4.0                              Kiến thức nhập môn IT   \n",
            "3    3             3.8                  Khóa học marketing online và SEO.   \n",
            "4    4             4.7                               Lập trình C++ cơ bản   \n",
            "5    5             4.9                          HTML CSS từ Zero đến Hero   \n",
            "6    6             3.5             Khóa học nấu ăn cho người mới bắt đầu.   \n",
            "7    7             4.2                         Responsive Với Grid System   \n",
            "8    8             3.9           Khóa học về phân tích dữ liệu với Excel.   \n",
            "9    9             4.4                        Lập Trình JavaScript Cơ Bản   \n",
            "10  10             4.1            Khóa học về lập trình ứng dụng di động.   \n",
            "11  11             4.6                      Lập Trình JavaScript Nâng Cao   \n",
            "12  12             4.3                Làm việc với Terminal & Ubuntu Khóa   \n",
            "13  13             4.8                  Xây Dựng Website với ReactJS Khóa   \n",
            "14  14             4.5        Khóa học miễn phí về đồ họa 3D với Blender.   \n",
            "15  15             4.1            Khóa học miễn phí về kỹ năng giao tiếp.   \n",
            "16  16             4.0  Khóa học miễn phí về phân tích dữ liệu với Pyt...   \n",
            "17  17             4.4         Khóa học miễn phí về viết blog thành công.   \n",
            "18  18             4.2            Khóa học miễn phí về tâm lý học cơ bản.   \n",
            "19  19             4.9  Khóa học miễn phí về làm video với Adobe Premi...   \n",
            "20  20             4.7          Khóa học miễn phí về phát triển bản thân.   \n",
            "\n",
            "    original_price  course_id  sub_category_id  \n",
            "0           100000        1.0              2.0  \n",
            "1           120000        2.0              2.0  \n",
            "2           120000        2.0              1.0  \n",
            "3           120000        3.0              2.0  \n",
            "4                0        4.0              2.0  \n",
            "5                0        5.0              2.0  \n",
            "6               50        6.0              2.0  \n",
            "7                0        7.0              2.0  \n",
            "8               75        8.0              2.0  \n",
            "9                0        9.0              2.0  \n",
            "10             150        NaN              NaN  \n",
            "11               0        NaN              NaN  \n",
            "12               0        NaN              NaN  \n",
            "13               0        NaN              NaN  \n",
            "14               0        NaN              NaN  \n",
            "15               0        NaN              NaN  \n",
            "16               0        NaN              NaN  \n",
            "17               0        NaN              NaN  \n",
            "18               0        NaN              NaN  \n",
            "19               0        NaN              NaN  \n",
            "20          100000        NaN              NaN  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from underthesea import word_tokenize\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def preprocess_vietnamese(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "def get_effective_price(row, courses_discount):\n",
        "    \"\"\"\n",
        "    Get the effective price considering discounts\n",
        "    \"\"\"\n",
        "    course_id = row['id']\n",
        "    original_price = row['original_price']\n",
        "\n",
        "    # Check if course has an active discount\n",
        "    discount_info = courses_discount[\n",
        "        (courses_discount['course_id'] == course_id) &\n",
        "        (courses_discount['is_active'] == True)\n",
        "    ]\n",
        "\n",
        "    if not discount_info.empty:\n",
        "        return discount_info.iloc[0]['discount_price']\n",
        "    return original_price\n",
        "\n",
        "def calculate_combined_similarity(courses, courses_discount, text_weight=0.6, rating_weight=0.2, price_weight=0.2, category_weight=0.9):\n",
        "    \"\"\"\n",
        "    Calculate similarity between courses based on description, rating, and effective price\n",
        "\n",
        "    Parameters:\n",
        "    - courses: DataFrame containing 'id', 'description', 'average_rating', and 'original_price'\n",
        "    - courses_discount: DataFrame containing discount information\n",
        "    - text_weight: weight for description similarity (default: 0.6)\n",
        "    - rating_weight: weight for rating similarity (default: 0.2)\n",
        "    - price_weight: weight for price similarity (default: 0.2)\n",
        "\n",
        "    Returns:\n",
        "    - combined similarity matrix\n",
        "    \"\"\"\n",
        "    # Preprocess description\n",
        "    courses['description'] = courses['description'].apply(preprocess_vietnamese)\n",
        "\n",
        "    # Calculate text similarity\n",
        "    tfidf = TfidfVectorizer(\n",
        "        max_features=3522,\n",
        "        ngram_range=(1, 2)\n",
        "    )\n",
        "    text_vectors = tfidf.fit_transform(courses['description'])\n",
        "    text_similarity = cosine_similarity(text_vectors)\n",
        "\n",
        "    # Calculate effective prices considering discounts\n",
        "    courses['effective_price'] = courses.apply(\n",
        "        lambda row: get_effective_price(row, courses_discount),\n",
        "        axis=1\n",
        "    )\n",
        "    # Normalize numerical features\n",
        "    scaler = MinMaxScaler()\n",
        "\n",
        "    # Handle rating similarity\n",
        "    ratings = courses[['average_rating']].values\n",
        "    normalized_ratings = scaler.fit_transform(ratings)\n",
        "    rating_similarity = 1 - np.abs(normalized_ratings - normalized_ratings.T)\n",
        "\n",
        "    # Handle price similarity using effective prices\n",
        "    prices = courses[['effective_price']].values\n",
        "    normalized_prices = scaler.fit_transform(prices)\n",
        "    price_similarity = 1 - np.abs(normalized_prices - normalized_prices.T)\n",
        "\n",
        "    # Handle category similarity: 1 if categories match, 0 if they don't\n",
        "    categories = courses[['sub_category_id']].values\n",
        "    category_similarity = np.array([[1 if cat1 == cat2 else 0 for cat2 in categories] for cat1 in categories])\n",
        "\n",
        "    # Combine all similarities with their respective weights\n",
        "    combined_similarity = (\n",
        "        text_weight * text_similarity +\n",
        "        rating_weight * rating_similarity +\n",
        "        price_weight * price_similarity +\n",
        "        category_weight * category_similarity\n",
        "    )\n",
        "\n",
        "    return combined_similarity\n",
        "\n",
        "# Load data\n",
        "courses = pd.read_csv('drive/MyDrive/Data_PRSE/course.csv')\n",
        "courses_discount = pd.read_csv('drive/MyDrive/Data_PRSE/course_discount.csv')\n",
        "courses_category = pd.read_csv('drive/MyDrive/Data_PRSE/course_category.csv')\n",
        "# Select required columns\n",
        "courses = courses[['id', 'average_rating', 'description', 'original_price']]\n",
        "courses = courses.merge(courses_category[['course_id', 'sub_category_id']], left_on='id', right_on='course_id', how='left')\n",
        "print(courses)\n",
        "# Calculate similarity matrix with effective prices\n",
        "similarity_matrix = calculate_combined_similarity(\n",
        "    courses,\n",
        "    courses_discount,\n",
        "    text_weight=0.75,\n",
        "    rating_weight=0.5,\n",
        "    price_weight=0.4\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}